{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundation Data Sciences\n",
    "## Semester 2 - Week 03: Estimation of confidence intervals with the bootstrap\n",
    "\n",
    "**Learning outcomes:** In this lab you will use statistical simulations to undertake bootstrap estimation of confidence intervals. By the end of this lab you should be able to:\n",
    "- code the bootstrap estimator for a number of estimators\n",
    "- validate statistical coding by comparing the output of functions with known results\n",
    "- interpret the output\n",
    "- compare the output with confidence intervals obtained by other methods\n",
    "\n",
    "We will go over simulations and randomness, from the topic on \"Estimation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf # Regression library\n",
    "from scipy.stats import norm # Object to with member functions to do with normal distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Bootstrap - confidence intervals\n",
    "\n",
    "Confidence intervals give us an indication of how sure we can be that an estimate lies within particular bounds. More precisely, we can state with a specified degree of certainty the chance that the true parameter lies in the confidence interval. For example, a 95% confidence interval has a chance of 0.95 of containing the true value. There is a trade-off between width and certainty: we can increase the width of the interval to be more certain (e.g. 99% certain).\n",
    "\n",
    "We'll finish off what we started on the basketball data set in the previous lab. We had got to the point of generating the sample mean of samples of the age and salary. We'd now like to extend that code to generate confidence intervals for various statistics in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data = pd.read_csv(\"datasets/player_data.csv\")\n",
    "salary_data = pd.read_csv(\"datasets/salary_data.csv\")\n",
    "full_data = pd.merge(salary_data, player_data,\n",
    "                     left_on=\"PlayerName\", right_on=\"Name\")\n",
    "full_data['Salary']=full_data['Salary']/1000000\n",
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 01:** Using the code from last week, and the information in the lecture notes, write a bootstrap estimation routine with $k=1000$ replications to:\n",
    "1. plot the sampling distribution of the mean.\n",
    "2. find a 95% confidence interval for the mean of the salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering a bootstrap function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in the lab, we are going to apply the bootstrap to a different estimator, and also run it repeatedly. We'd therefore like to turn it into a function.\n",
    "\n",
    "**Exercise 02:** Write a function called bootstrap(), which takes as its input arguments:\n",
    "1. `x`: pd.Series()\n",
    "3. `estimator`: The function (e.g. `np.mean`) that you would like to get the bootstrap confidence intervals for. Note that you can pass functions as arguments to python functions.\n",
    "4. `quantiles`: An array containing the desired quantiles\n",
    "5. `plot`: Boolean indicating if a plot of the bootstrap distribution of the estimator should be shown. `False` by default.\n",
    " \n",
    "It should return:\n",
    "1. the quantiles\n",
    "2. the bootstrap standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to deploy code you should always check that each function actually does what it is supposed to do. A good habit is to do what is called *unit testing* -  a method by which units of the code are checked for correctness. These are typically short code snippets that check automatically that the output of a function is as intended. In our setting, however, this would be an overkill, and we can just check manually whether our function has the correct output on a known setting. In this, artificial, case we know the distribution, so we can estimate the SEM as $\\sigma_{\\overline{X}} = \\sigma/\\sqrt{n}$ . \n",
    "\n",
    "**Exercise 03:** \n",
    "- Compare the SEM computed from the full distribution with the bootstrap estimates.\n",
    "- Are they of a similar size? If so, good - if not, go back and check the bootstrap function.\n",
    "- Compare the quantiles produced by the function with the distribution produced with `plot=True`. Do the quantiles lie in the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the bootstrap function to the median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap is very flexible - here we use it to find confidence intervals for the median, rather than the mean.\n",
    "\n",
    "**Exercise 04:** Apply your new bootstrap function to the confidence intervals of the median of the salaries, plotting the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Does the distribution of the sample median look as you would expect it to? If not, what is unusual about it? Can you explain why you're seeing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the confidence interval to the theoretical value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 05:** Determine the confidence interval for *the mean* using the theoretical method (not bootstrap), assuming a normal distribution of the mean. **Hint:** The documentation for `scipy.stats.norm.isf()` may be helpful. Compare it with the results you got in **Exercises 02 and 03**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Bootstrap applied to linear regression -  output from other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've said in the lectures, we can apply the bootstrap estimator to many different types of statistic, where by \"statistic\" we mean a value derived from the data. Above, for example, we have already used the median instead of the mean. Linear regression coefficients also count as statistics - so we should be able to used the bootstrap on them.\n",
    " \n",
    " **Exercise 06:** \n",
    " - Create a new column of `full_data` called `LogSalary`, which is the log to the base 10 of `Salary`.\n",
    " - Plot the `LogSalary` against the `Age`.\n",
    " - Fit a linear regression of the `LogSalary` to the `Age` using `statsmodels`. (See the linear regression lab).\n",
    " - Extract the best fitting `Intercept` parameter and slope parameter (called `Age`) from the result. Hint: use the `params` member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 07:** Now use the code from exercise 06 to:\n",
    "\n",
    "- Write a function `beta0hat` that, given a data frame `df` with the same format as `full_data` returns the fitted intercept. \n",
    "- Write a function `beta1hat` that returns the fitted slope (`Age`) parameter. \n",
    "- Test that it gets the correct results, when given full_data as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 08:** \n",
    "- Write a function `bootstrap_df`, which is the same as `bootstrap`, but in which the estimator can take a DataFrame as an argument, and return a statistic (i.e., just like the function `beta0hat` does).\n",
    "- Write a function `salary_mean()` that returns the mean of the `Salary` column of a data frame, and use it to verify that `bootstrap_df` gives similar results to the ones you obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 09:**\n",
    "Now apply the `bootstrap_df` function to get confidence intervals of\n",
    "1. The `Intercept` coefficient $\\hat\\beta_0$ of the linear regression of `Age` on `LogSalary`.\n",
    "2. The slope coefficient $\\hat\\beta_1$ of the linear regression of `Age` on `LogSalary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Comparison of bootstrap and theoretical confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we don't actually have to use the bootstrap to estimate the confidence intervals; statsmodels (and many other packages) can estimate the standard error of the sampling distribution of the estimator. Run the statsmodels fit again, but this time report all the output using the `summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('LogSalary ~ Age', data=full_data)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the middle table of the results, containing the `Intercept` and `Age` variables. In semester 1 we learned how to interpret the `coeff` column. We should now be able to understand the `std err` and `[0.025` and `0.975]` columns. \n",
    "- `coeff`: best estimate of `Intercept` and `Age`\n",
    "- `std err`: the standard error of the estimators of `Intercept` and `Age`\n",
    "- `[0.025`: lower bound of the 95% confidence interval of the estimators of `Intercept` and `Age`\n",
    "- `0.025]`: upper bound of the 95% confidence interval of the estimators of `Intercept` and `Age`\n",
    "\n",
    "**Discussion**:\n",
    "- Are the standard errors reported here close to the bootstrap estimates? \n",
    "- Are the confidence intervals close to the bootstrap estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the confidence intervals are close to the bootstrap estimates. If not, check your bootstrap code again!\n",
    "\n",
    "We can now explain the `P>|t|` column. The `t` column refers to the `t` statistic: \n",
    "\n",
    "$t = \\frac{\\hat\\theta - 0}{\\hat\\sigma_{\\hat\\theta}}$\n",
    "\n",
    "It is a measure of the distance of the fitted parameter from 0. You can check that `t` does indeed equal the coefficient divided by the standard error.\n",
    "\n",
    "It has to do with a hypothesis test. The null and alternative hypotheses are:\n",
    "\n",
    "$H_0$: The true value of the parameter is equal to zero\n",
    "\n",
    "$H_\\mathrm{a}$: The parameter is equal to something else\n",
    "\n",
    "Due to the duality between confidence intervals and hypothesis testing, to test the null hypothesis we can consider the area in the tail of the sampling distribution beyond 0 to be the *p*-value. In the case of both the Age and the Salary, this *p*-value `P>|t|` is 0.  \n",
    "\n",
    "**Discussion:** Is the null hypothesis rejected or not? Does this make sense when you compare the confidence intervals to 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need your help:** This is a new course. In order for us to improve the labs for the next iterations, and to make sure that the next labs are better, we need your feedback. Please fill out the following [form](https://forms.office.com/Pages/ResponsePage.aspx?id=sAafLmkWiUWHiRCgaTTcYZmGMCx4KxlMjSTITqjdcXpURUJESTc3VkpXOFhBTkFVSks1MVc4UUZVSy4u)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
